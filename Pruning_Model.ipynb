{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ad2fe4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fdf21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e5ec55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "060a190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec5ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Images\n",
    "\n",
    "# Normalize the image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f6ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model architecture\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "\n",
    "  keras.layers.Conv2D(filters=24, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "  keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128),\n",
    "  keras.layers.Dense(64),\n",
    "  keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76d6812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 24)        240       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 24)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 12)        2604      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 12)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 8)           872       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1152      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,774\n",
      "Trainable params: 13,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3cbc0",
   "metadata": {},
   "source": [
    "# A) Before Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4660629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the compiler\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61481a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 22s 12ms/step - loss: 0.7298 - accuracy: 0.7261 - val_loss: 0.5689 - val_accuracy: 0.7937\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.5137 - accuracy: 0.8137 - val_loss: 0.4952 - val_accuracy: 0.8165\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.4673 - accuracy: 0.8308 - val_loss: 0.4536 - val_accuracy: 0.8318\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 18s 11ms/step - loss: 0.4400 - accuracy: 0.8419 - val_loss: 0.4166 - val_accuracy: 0.8490\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 18s 11ms/step - loss: 0.4232 - accuracy: 0.8486 - val_loss: 0.4176 - val_accuracy: 0.8487\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 18s 10ms/step - loss: 0.4093 - accuracy: 0.8524 - val_loss: 0.4129 - val_accuracy: 0.8503\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 20s 12ms/step - loss: 0.4001 - accuracy: 0.8573 - val_loss: 0.4166 - val_accuracy: 0.8513\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 18s 10ms/step - loss: 0.3905 - accuracy: 0.8609 - val_loss: 0.4074 - val_accuracy: 0.8548\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.3829 - accuracy: 0.8626 - val_loss: 0.3993 - val_accuracy: 0.8542\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.3798 - accuracy: 0.8634 - val_loss: 0.3986 - val_accuracy: 0.8585\n",
      "Time Taken for Training : 183.17078543\n"
     ]
    }
   ],
   "source": [
    "# Calculating Training time\n",
    "start = time.time() #starting\n",
    "\n",
    "#Training\n",
    "model.fit(train_images, train_labels, epochs=10, validation_split=0.1)\n",
    "\n",
    "end = time.time() #stoping\n",
    "\n",
    "temp = end - start\n",
    "print ('Time Taken for Training : %.8f'%temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3f60d",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50566697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8535000085830688\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Accuracy : \",score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665b0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e21d0ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Prediction :  Trouser\n",
      "Actual Value:  Trouser\n",
      "Time Taken for predicting one data point : 0.08233523\n"
     ]
    }
   ],
   "source": [
    "#calculating time taken for predicting one image\n",
    "\n",
    "image = test_images[5]             # image shape = (28, 28)\n",
    "image = image.reshape(1, 28, 28)   # image shape = (1, 28, 28)\n",
    "\n",
    "start = time.time() #starting\n",
    "\n",
    "#Predicting\n",
    "predictions = model.predict(image)\n",
    "print(\"Prediction : \",class_names[np.argmax(predictions[0])])\n",
    "\n",
    "end = time.time() #stoping\n",
    "\n",
    "print(\"Actual Value: \",class_names[test_labels[5]])\n",
    "\n",
    "temp=end - start\n",
    "print ('Time Taken for predicting one data point : %.8f'%temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098cf6b",
   "metadata": {},
   "source": [
    "# Calculating the size of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8511ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43153d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of model :  223096\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of model : \",os.stat('model.h5').st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a618d54",
   "metadata": {},
   "source": [
    "# B) After Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cd0ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "validation_split = 0.1  \n",
    "\n",
    "n_images = train_images.shape[0] * (1 - validation_split) #calculating number of images in training set after subtracting validation set\n",
    "last_step = np.ceil(n_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_para = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=last_step)\n",
    "}\n",
    "\n",
    "pruning_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ccd153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the compiler\n",
    "pruning_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#adding callbacks\n",
    "callback = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=tempfile.mkdtemp()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "291cde7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 14s 26ms/step - loss: 0.4384 - accuracy: 0.8377 - val_loss: 0.4353 - val_accuracy: 0.8372\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.4156 - accuracy: 0.8460 - val_loss: 0.4237 - val_accuracy: 0.8430\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 11s 25ms/step - loss: 0.4045 - accuracy: 0.8514 - val_loss: 0.4209 - val_accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.4010 - accuracy: 0.8528 - val_loss: 0.4266 - val_accuracy: 0.8423\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 10s 25ms/step - loss: 0.4017 - accuracy: 0.8525 - val_loss: 0.4364 - val_accuracy: 0.8377\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.4090 - accuracy: 0.8486 - val_loss: 0.4316 - val_accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.4121 - accuracy: 0.8488 - val_loss: 0.4309 - val_accuracy: 0.8437\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.4134 - accuracy: 0.8482 - val_loss: 0.4383 - val_accuracy: 0.8390\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 11s 25ms/step - loss: 0.4158 - accuracy: 0.8478 - val_loss: 0.4315 - val_accuracy: 0.8435\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.4115 - accuracy: 0.8487 - val_loss: 0.4304 - val_accuracy: 0.8440\n",
      "Time Taken for Training : 107.89374828\n"
     ]
    }
   ],
   "source": [
    "# Calculating Training time\n",
    "start = time.time() #starting\n",
    "\n",
    "#Training\n",
    "pruning_model.fit(train_images, train_labels,batch_size = batch_size, epochs=epochs, validation_split=validation_split,callbacks=callback)\n",
    "\n",
    "end = time.time() #stoping\n",
    "\n",
    "temp = end - start\n",
    "print ('Time Taken for Training : %.8f'%temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd291dc",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6fb2f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Test loss: 0.4535457491874695\n",
      "Pruned Test accuracy: 0.8378999829292297\n"
     ]
    }
   ],
   "source": [
    "score = pruning_model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Pruned Test loss:', score[0]) \n",
    "print('Pruned Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c3d908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n",
      "Prediction :  Trouser\n",
      "Actual Value:  Trouser\n",
      "Time Taken for predicting one data point : 0.24356222\n"
     ]
    }
   ],
   "source": [
    "#calculating time taken for predicting one image\n",
    "\n",
    "image = test_images[5]\n",
    "image = image.reshape(1, 28, 28)\n",
    "\n",
    "start = time.time() #starting\n",
    "\n",
    "#Predicting\n",
    "predictions = pruning_model.predict(image)\n",
    "print(\"Prediction : \",class_names[np.argmax(predictions[0])])\n",
    "\n",
    "end = time.time() #stoping\n",
    "\n",
    "print(\"Actual Value: \",class_names[test_labels[5]])\n",
    "\n",
    "temp=end - start\n",
    "print ('Time Taken for predicting one data point : %.8f'%temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572837f",
   "metadata": {},
   "source": [
    "# Calculating the size of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7142e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing compression on the model\n",
    "final_model = tfmot.sparsity.keras.strip_pruning(pruning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce6d8ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Size of model :  88432\n"
     ]
    }
   ],
   "source": [
    "final_model.save('model2.h5') \n",
    "\n",
    "print(\"Size of model : \",os.stat('model2.h5').st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d2956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
